import json
import os
import random
import re
from datetime import datetime

import matplotlib
import torch
from matplotlib import pyplot as plt
from transformers import AutoModel
import networkx as nx
import numpy as np
import pickle

# from 测试2 import 语言模型
# from 语言模型函数 import 语言模型
from lms语言函数 import 语言模型
import pyttsx3

# 初始化 pyttsx3 引擎
engine = pyttsx3.init()

# 设置语音参数（可选）
engine.setProperty('rate', 200)  # 设置语速，默认是 200
engine.setProperty('volume', 1)  # 设置音量，范围是 0.0 到 1.0

matplotlib.rcParams['font.sans-serif'] = ['SimHei']  # 或 'Microsoft YaHei'
matplotlib.rcParams['axes.unicode_minus'] = False  # 解决负号 '-' 显示问题

# 获取当前文件夹路径
当前文件夹 = os.path.dirname(os.path.abspath(__file__))

# 设置模型下载路径为当前文件夹
模型路径 = os.path.join(当前文件夹, "模型文件夹")

# Initialize the model
model = AutoModel.from_pretrained("jinaai/jina-embeddings-v3", trust_remote_code=True, cache_dir=模型路径,
                                  device_map="cuda", torch_dtype=torch.float16,
                                  )


# code_revision='da863dd04a4e5dce6814c6625adfba87b83838aa',
# texts1 = [
#  "蕾米莉亚大小姐"
# ]
#
# texts2 = [
#  "东方project"
# ]
#
# # When calling the `encode` function, you can choose a `task` based on the use case:
# # 'retrieval.query', 'retrieval.passage', 'separation', 'classification', 'text-matching'
# # Alternatively, you can choose not to pass a `task`, and no specific LoRA adapter will be used.
# embeddings1 = model.encode(texts1, task="text-matching")
# embeddings2 = model.encode(texts2, task="text-matching")
# # Compute similarities
# print(embeddings1[0] @ embeddings2[0].T)

def 格式化日期时间(时间字符串):
    try:
        # 解析原始时间字符串
        原始时间 = datetime.strptime(时间字符串, "%Y-%m-%dT%H:%M:%S.%f")

        # 提取年份、月份、日期、小时和分钟
        年份 = str(原始时间.year)[2:]  # 取年份的后两位
        月份 = 原始时间.month
        日期 = 原始时间.day
        小时 = 原始时间.hour
        分钟 = 原始时间.minute

        # 格式化为目标字符串
        格式化后的时间 = f"{年份}年{月份}月{日期}日{小时}点{分钟}分"

        return 格式化后的时间
    except Exception as e:
        return 时间字符串


def 获取当前时间():
    # 获取当前时间
    当前时间 = datetime.now()

    # 格式化日期
    年份 = 当前时间.year
    月份 = 当前时间.month
    日子 = 当前时间.day
    小时 = 当前时间.hour
    分钟 = 当前时间.minute

    # 判断时间段（早晨/上午/中午/下午/傍晚/晚上/凌晨/清晨）
    if 5 <= 小时 < 7:
        时间段 = "清晨"
    elif 7 <= 小时 < 9:
        时间段 = "早晨"
    elif 9 <= 小时 < 12:
        时间段 = "上午"
    elif 12 <= 小时 < 14:
        时间段 = "中午"
    elif 14 <= 小时 < 18:
        时间段 = "下午"
    elif 18 <= 小时 < 20:
        时间段 = "傍晚"
    elif 20 <= 小时 < 24:
        时间段 = "晚上"
    else:
        时间段 = "凌晨"

    # 格式化时间部分
    格式化时间 = f"{年份}年{月份}月{日子}日，{时间段} {小时}时{分钟}分"
    return 格式化时间


def 扩散系数(x):
    if 0.0 <= x <= 1.0:
        return 1.0 + 4.0 * x ** 2.0
    else:
        raise ValueError("输入值必须在 [0, 1] 之间")


def 词嵌入函数(内容):
    return model.encode(内容, task="text-matching")


def 节点内容创建函数(节点信息, 使用次数=0, 激活状态=1, 固定记忆参数=0, 休眠论数=0, 添加日期=获取当前时间()):
    节点嵌入向量 = model.encode(节点信息, task="text-matching")
    节点数组 = [节点嵌入向量, 节点信息, 使用次数, 激活状态, 固定记忆参数, 休眠论数, 添加日期]
    return 节点数组


def 添加节点(图, 要加入的节点):
    节点名称 = ''.join([str(random.randint(0, 9)) for _ in range(10)])
    图.add_node(要加入的节点[1], 属性=要加入的节点)


def 加载节点(图, 节点名称):
    节点信息 = 图.nodes[节点名称]["属性"]
    return 节点信息


def 添加节点总(节点信息, 图):
    节点数组 = 节点内容创建函数(节点信息)
    添加节点(图, 节点数组)


def 添加边(节点1, 节点2, 图, 属性):
    for 节点 in 图.nodes:
        if (图.nodes[节点]["属性"])[1] == 节点1:
            节点名称1 = 节点
            向量1 = (图.nodes[节点]["属性"])[0]
        if (图.nodes[节点]["属性"])[1] == 节点2:
            向量2 = (图.nodes[节点]["属性"])[0]
            节点名称2 = 节点
    try:
        图.add_edge(节点名称1, 节点名称2, 属性=属性, 距离=扩散系数(1.0 - (向量1 @ 向量2.T)), 创建日期=获取当前时间())
    except Exception as e:
        print("名称出错!无此节点!请检查节点名称")


def 遍历边(图):
    数据 = ""
    for 节点1, 节点2, 属性 in 图.edges(data=True):
        距离 = 属性['距离']
        距离 = "{:.4f}".format(float(距离))
        属性1 = 属性["属性"]
        添加日期 = 属性["创建日期"]
        添加日期 = 格式化日期时间(str(添加日期))
        # print(f"实体1: {节点1},实体2: {节点2}, 实体关系: {属性},距离:{距离}")
        数据 = 数据 + f"实体1: {节点1},实体2: {节点2}, 实体关系: {属性1},距离:{距离},边添加日期:{添加日期}" + "\n"
    return 数据


def 遍历节点(图, 属性值=1):
    数据 = ""
    # print("节点遍历:")
    for 节点 in 图.nodes:
        属性 = 图.nodes[节点]["属性"]
        # print(属性[属性值])
        数据 = 数据 + 属性[属性值] + "   添加日期:" + 格式化日期时间(属性[6]) + "\n"
    return 数据


def 绘制图(图):
    # 绘制图
    nx.draw(图, with_labels=True, node_color='lightblue', node_size=2000, font_size=16, font_weight='bold',
            edge_color='gray')
    # 显示图
    plt.show()


def 节点融合函数(新图, 老图):
    pass


def 字符串转换为json(字符串):
    # 使用json.loads()将字符串转换为Python字典（JSON数据结构）
    if 字符串.startswith("```json") and 字符串.endswith("```"):
        字符串 = 字符串[7:-3].strip()  # 去掉 ```json 和 ```

    json_data = json.loads(字符串)
    return json_data


def 转换json为数组(json_data):
    # 获取节点数组
    节点 = json_data["节点"]

    # 获取边数组
    边 = []
    for 边项 in json_data["边"]:
        边列表 = [边项["节点1"], 边项["节点2"], 边项["属性"]]
        边.append(边列表)

    return 节点, 边


def 创建图关系(节点数组, 边数组):
    图 = nx.Graph()
    for 节点 in 节点数组:
        添加节点总(节点, 图)
    for 边 in 边数组:
        添加边(边[0], 边[1], 图, 边[2])
    return 图


def 输入信息生成知识图谱(信息):
    消息 = [
        {"role": "system", "content": """
    请根据用户输入信息生成一个JSON格式的输出，用于构建知识图谱：  
    ### 注意事项：  
    1. 输出的JSON结构必须包括：  
       - **“节点”部分**：列出所有与设定相关的唯一元素，如人物、地点、事件、性格描述等，确保节点不重复。  
       - **“边”部分**：清晰描述这些节点之间的关系，每条边需准确使用“节点”部分中已列出的节点，不能生成未在“节点”部分列出的节点。  
    2. **节点顺序**：先生成完整的节点列表，确保所有边中的节点都出现在“节点”部分，确保所有边中的节点都出现在“节点”部分非常重要!!。  
    3. **边描述要求**：每条边必须包含： 
       - **节点1**：关联的第一个节点。  
       - **节点2**：关联的第二个节点。  
       - **属性**：简洁且明确地表达两节点间的关系。  
    ### JSON格式示例：  
    示例输入：  
    "在东方project的设定中，蕾米莉亚和芙兰朵露是姐妹关系，生活在红魔馆这一地点，而幻想乡是该系列的世界设定。芙兰朵露虽然平常不容易生气，但存在一定的精神问题。"  
    示例输出：  
    ```json
    {
        "节点": [
            "蕾米莉亚",
            "东方project",
            "芙兰朵露",
            "幻想乡",
            "红魔馆",
            "平常并不太易怒，但精神有些问题。"
        ],
        "边": [
            {"节点1": "蕾米莉亚", "节点2": "东方project", "属性": "蕾米莉亚属于东方project这个游戏"},
            {"节点1": "芙兰朵露", "节点2": "东方project", "属性": "芙兰朵露属于东方project这个游戏"},
            {"节点1": "幻想乡", "节点2": "东方project", "属性": "幻想乡是东方project这个游戏里的世界名称"},
            {"节点1": "红魔馆", "节点2": "东方project", "属性": "红魔馆是东方project这个游戏世界里的一个地区"},
            {"节点1": "蕾米莉亚", "节点2": "芙兰朵露", "属性": "蕾米莉亚是芙兰朵露的姐姐"},
            {"节点1": "蕾米莉亚", "节点2": "红魔馆", "属性": "蕾米莉亚住在红魔馆"},
            {"节点1": "芙兰朵露", "节点2": "红魔馆", "属性": "芙兰朵露住在红魔馆"},
            {"节点1": "平常并不太易怒，但精神有些问题。", "节点2": "芙兰朵露", "属性": "芙兰朵露的性格"}
        ]
    }
    ```  
    ### 强制要求：  
    1. **节点部分必须完整且唯一**：生成的“边”部分只能引用你已列出的“节点”,生成的“边”部分只能引用你已列出的“节点”这非常重要,非常重要!!!!
    比如{"节点1": "蕾米莉亚", "节点2": "东方project", "属性": "蕾米莉亚属于东方project这个游戏"},里的节点1和节点2,必须是"节点"里有的!!!。  
    2. **只生成一次JSON输出**，且严格按照上述示例格式，保持清晰、无冗余内容。  
    3. **描述准确**：节点和边的关系必须基于输入信息，不能添加未提到的设定或内容。  
    4. 确保JSON格式严格正确，避免任何语法错误。  
    5. 在输入知识性信息时,请生成完整的知识图谱。 
    6. 如果你要记忆某件事可以用这样的关系处理 比如 {"节点1": "事情x", "节点2": "事情主角1", "属性": "事情主角1发生了xxxx"}
        如果有多个主角或事物按照  {"节点1": "事情x", "节点2": "事情主角1", "属性": "事情主角1和事情主角2发生了xxxx"}
                                {"节点1": "事情x", "节点2": "事情主角2", "属性": "事情主角2和事情主角1发生了xxxx"}
                                {"节点1": "事情x", "节点2": "事情事物", "属性": "事情主角1发生了xxxx"} ...,
                                总之,灵活处理生成记忆图谱,不过你必须记住生成的“边”部分只能引用你已列出的“节点”这非常重要,非常重要!!!!
    """},
        {"role": "user", "content": 信息}
    ]

    while True:  # 重试机制
        try:
            输出 = str(语言模型(消息))  # 调用语言模型获取输出
            输出 = 字符串转换为json(输出)  # 将输出转换为 JSON 格式
            节点数组, 边数组 = 转换json为数组(输出)  # 转换 JSON 为节点和边的数组
            图 = 创建图关系(节点数组, 边数组)  # 创建图关系
            print("成功执行:输入信息生成知识图谱")
            return 图  # 返回生成的图

        except (json.JSONDecodeError, KeyError) as e:
            # 如果在 JSON 转换或数组转换时出错，打印错误并重新生成输出
            print(f"错误发生：{e}，正在重新生成输出...")
            continue  # 继续重试


def 合成图(图1, 图2):
    # 创建一个新图，复制图1
    合成后的图 = nx.Graph()
    合成后的图.add_nodes_from(图1.nodes(data=True))
    合成后的图.add_edges_from(图1.edges(data=True))

    # 合并图2的节点
    for 节点, 属性 in 图2.nodes(data=True):
        if 节点 not in 合成后的图:
            # 如果节点不在图1，直接添加
            合成后的图.add_node(节点, **属性)
        else:
            # 如果节点名字相同，则属性已相同，无需操作
            pass

    # 合并图2的边
    for 边起点, 边终点, 边属性 in 图2.edges(data=True):
        if not 合成后的图.has_edge(边起点, 边终点):
            合成后的图.add_edge(边起点, 边终点, **边属性)

    # 遍历合成后的图中所有节点，检查是否需要创建新边
    for 节点1, 属性1 in 合成后的图.nodes(data=True):
        for 节点2, 属性2 in 合成后的图.nodes(data=True):
            if 节点1 != 节点2:
                # 检查节点1和节点2的激活状态
                if 属性1["属性"][3] == 0 or 属性2["属性"][3] == 0:
                    continue  # 如果任何一个节点的激活状态为0，则跳过这对节点，不创建边

                # 假设虚拟条件：如果两个节点属性中“激活状态”都为1
                判别 = float(属性1["属性"][0] @ 属性2["属性"][0].T)

                if 判别 >= 0.7:
                    # 如果满足条件，添加新边
                    if not 合成后的图.has_edge(节点1, 节点2):
                        合成后的图.add_edge(
                            节点1, 节点2,
                            属性="此边为系统自动合成,语义相似度为:" + str(round(判别, 4)) +
                                 "(1为完全相同的语义,0为完全没有语义上的联系)",
                            距离=扩散系数(1.0 - 判别),
                            创建日期=获取当前时间()
                        )

    return 合成后的图


# def 提取子图(图, 起始节点, 最大距离, 选择数量):
#     # 计算从起始节点的加权最短路径
#     距离字典 = nx.single_source_dijkstra_path_length(图, 起始节点, weight="距离")
#
#     # 找出满足距离条件的节点，并按距离排序
#     满足条件的节点 = sorted(
#         [(节点, 距离) for 节点, 距离 in 距离字典.items() if 距离 <= 最大距离],
#         key=lambda x: x[1]
#     )
#
#     # 限制为前 选择数量 个节点
#     满足条件的节点 = [节点 for 节点, _ in 满足条件的节点[:选择数量]]
#
#     for 节点 in 满足条件的节点:  # 给使用次数+1
#         当前属性 = 图.nodes[节点]["属性"]
#
#         # 修改属性，例如修改使用次数和激活状态
#         当前属性[2] += 1  # 使用次数 +1
#         当前属性[5] = 0
#         # 更新节点的属性
#         图.nodes[节点]["属性"] = 当前属性
#
#     # 提取子图
#     子图 = 图.subgraph(满足条件的节点).copy()
#     return 子图


def 提取子图(图, 起始节点, 最大距离, 选择数量):
    # 计算从起始节点的加权最短路径
    距离字典 = nx.single_source_dijkstra_path_length(图, 起始节点, weight="距离")

    # 找出满足距离条件的节点，并按距离从小到大排序
    满足条件的节点 = sorted(
        [(节点, 距离) for 节点, 距离 in 距离字典.items() if 距离 <= 最大距离],
        key=lambda x: x[1]
    )

    阈值 = 10  # 固定选择的前10个节点

    if 选择数量 <= 阈值:
        # 如果选择数量小于等于阈值，直接取前选择数量个节点
        满足条件的节点 = [节点 for 节点, _ in 满足条件的节点[:选择数量]]
    else:
        # 固定选择前阈值个节点
        确定选择的节点 = [节点 for 节点, _ in 满足条件的节点[:阈值]]

        # 剩余部分用于随机选择
        剩余节点 = 满足条件的节点[阈值:]  # 从第阈值名之后开始
        节点列表 = [节点 for 节点, _ in 剩余节点]
        距离列表 = np.array([距离 for _, 距离 in 剩余节点])

        if len(节点列表) > 0:
            # 计算概率：距离越小，概率越大
            概率 = 1 / (距离列表 + 1e-6)  # 避免除以0
            概率 /= 概率.sum()  # 归一化

            # 随机选择剩余节点
            随机选择的节点 = list(np.random.choice(
                节点列表,
                size=min(len(节点列表), 选择数量 - 阈值),
                replace=False,
                p=概率
            ))
        else:
            随机选择的节点 = []  # 没有剩余节点时，随机选择为空

        # 合并固定选择和随机选择的节点
        满足条件的节点 = 确定选择的节点 + 随机选择的节点

    # 确保路径连通性：添加随机节点路径上的中间节点及其边
    补充节点 = set()
    补充边 = set()
    for 节点 in 满足条件的节点:
        if nx.has_path(图, 起始节点, 节点):
            # 获取路径上的所有节点和边
            路径 = nx.shortest_path(图, source=起始节点, target=节点)
            补充节点.update(路径)
            补充边.update(zip(路径[:-1], 路径[1:]))  # 添加路径上的所有边

    # 合并原有节点和补充节点
    满足条件的节点 = list(set(满足条件的节点) | 补充节点)

    # 更新图结构，保留路径上的边
    子图 = 图.subgraph(满足条件的节点).copy()
    子图.add_edges_from(补充边)

    for 节点 in 子图.nodes:  # 给使用次数+1
        当前属性 = 图.nodes[节点]["属性"]

        # 修改属性，例如修改使用次数和激活状态
        当前属性[2] += 1  # 使用次数 +1
        当前属性[5] = 0
        # 更新节点的属性
        子图.nodes[节点]["属性"] = 当前属性

    return 子图


def 找相似节点(图, 输入嵌入向量, 筛选数量, 相似度阈值):
    节点相似度 = []

    # 遍历图中的所有节点，计算相似度
    for 节点名称, 节点属性 in 图.nodes(data=True):
        节点嵌入向量 = 节点属性["属性"][0]  # 提取嵌入向量
        相似度 = 输入嵌入向量 @ 节点嵌入向量.T  # 计算相似度
        if 相似度 > 相似度阈值:
            节点相似度.append((节点名称, 相似度))

    # 按相似度排序，取前 x 个节点
    节点相似度.sort(key=lambda x: x[1], reverse=True)
    筛选节点 = [节点名称 for 节点名称, _ in 节点相似度[:筛选数量]]

    for 节点 in 筛选节点:  # 给使用次数+1
        当前属性 = 图.nodes[节点]["属性"]
        # print("原始属性:", 当前属性)

        # 修改属性，例如修改使用次数和激活状态
        当前属性[2] += 1  # 使用次数 +1
        当前属性[5] = 0

        # 更新节点的属性
        图.nodes[节点]["属性"] = 当前属性
        # print("修改后的属性:", 图.nodes[节点]["属性"])

    return 筛选节点


def 检索图函数(图, 内容, 筛选数量, 相似度阈值, 检索深度, 检索数量=10):
    print("目前节点数量:" + str(图.number_of_nodes()))
    嵌入向量 = model.encode(内容, task="text-matching")
    节点列表 = 找相似节点(图, 嵌入向量, 筛选数量, 相似度阈值)
    图数组 = []

    if not 节点列表:
        # print("无检索结果")
        return 图数组

    for 节点 in 节点列表:
        子图 = 提取子图(图, 节点, 检索深度, 检索数量)
        print("子图节点占比:" + f"{(子图.number_of_nodes() / 图.number_of_nodes()) * 100:.2f}%")
        图数组.append(子图)
    return 图数组


# def 遍历图信息(图数组):
#     if not 图数组:
#         print("无图")
#
#     for 图 in 图数组:
#         print("---------------图----------------")
#         遍历节点(图, 属性值=1)
#         遍历边(图)
#         print("---------------------------------")

def 获取节点周围的边(图, 内容):
    图数组 = 检索图函数(图, 内容, 2, 0.2, 20, 检索数量=10)
    模型输入 = ""
    if not 图数组:
        return "无可用记忆"

    for 图 in 图数组:
        模型输入 = 模型输入 + "-------" + "\n"
        模型输入 = 模型输入 + str(遍历节点(图, 属性值=1))
        模型输入 = 模型输入 + str(遍历边(图))
        模型输入 = 模型输入 + "-------" + "\n"

    return 模型输入


def 提取整理记忆(图数组):
    模型输入 = ""
    if not 图数组:
        return "无可用记忆"

    for 图 in 图数组:
        模型输入 = 模型输入 + "-------" + "\n"
        模型输入 = 模型输入 + str(遍历节点(图, 属性值=1))
        模型输入 = 模型输入 + str(遍历边(图))
        模型输入 = 模型输入 + "-------" + "\n"

        # print(模型输入)

    消息 = [
        {"role": "system", "content": """根据用户输入的记忆图实体和节点提取出可被人类读取的信息
            要求:
            1.结果完整,不能遗漏任何信息
            2.语言精炼,不要啰嗦
            3.信息过多时可以分点输出,保证信息完整
            4.如果信息存在冲突,按照最新时间来
            """},
        {"role": "user", "content": 模型输入}
    ]

    输出 = str(语言模型(消息))
    return 输出


def 更新休眠论数(图):
    """
    遍历图中的每个节点，让所有节点的休眠论数加1。
    """
    for 节点, 属性 in 图.nodes(data=True):
        当前属性 = 属性["属性"]
        当前属性[5] += 1  # 休眠论数加1
        图.nodes[节点]["属性"] = 当前属性
    print("成功执行:更新休眠论数")


def 更新固定记忆参数(图, 使用次数阈值):
    """
    遍历图中的每个节点，当使用次数超过指定阈值时，将固定记忆参数设置为1。
    """
    for 节点, 属性 in 图.nodes(data=True):
        当前属性 = 属性["属性"]
        if 当前属性[2] > 使用次数阈值:  # 检查使用次数是否超过阈值
            当前属性[4] = 1  # 设置固定记忆参数为1
            图.nodes[节点]["属性"] = 当前属性
    print("成功执行:更新固定记忆参数")


def 更新激活状态(图, 休眠轮数阈值):
    """
    遍历图中的每个节点，当休眠轮数超过指定阈值时，将激活状态设置为0，并将休眠轮数重置为0。
    """
    for 节点, 属性 in 图.nodes(data=True):
        当前属性 = 属性["属性"]
        if 当前属性[5] > 休眠轮数阈值:  # 检查休眠轮数是否超过阈值
            当前属性[3] = 0  # 设置激活状态为0
            当前属性[5] = 0  # 重置休眠轮数为0
            图.nodes[节点]["属性"] = 当前属性
    print("成功执行:更新激活状态")


def 删除休眠节点(图, 休眠轮数阈值):
    """
    删除休眠轮数超过指定阈值且激活状态为0的节点以及相关的边。
    """
    删除节点列表 = []

    # 遍历节点，标记需要删除的节点
    for 节点, 属性 in 图.nodes(data=True):
        当前属性 = 属性["属性"]
        if 当前属性[5] > 休眠轮数阈值 and 当前属性[3] == 0:  # 检查条件
            删除节点列表.append(节点)

    # 从图中删除标记的节点及其相关的边
    图.remove_nodes_from(删除节点列表)
    print("成功执行:删除休眠节点")


def 更新记忆函数(图, 聊天记录, 使用次数阈值=10, 休眠轮数阈值=30, 删除休眠轮数阈值=20):
    更新休眠论数(图)
    更新固定记忆参数(图, 使用次数阈值)
    更新激活状态(图, 休眠轮数阈值)
    删除休眠节点(图, 删除休眠轮数阈值)
    聊天记录 = [entry for entry in 聊天记录 if entry["role"] != "system"]

    信息 = [{"role": "system", "content": """
    以下是多轮对话记录，请从中提取出有用的信息，并将其总结为一段详细的记忆信息。要求信息全面、清晰，并涵盖以下要素：
    1. 关键人物：提到的所有重要角色，包括人物的名称、性格特点、背景信息、关系等。
    2. 重要事件：对话中涉及的重要事件、决策、目标等，并确保这些事件的背景和相关细节完整保留。
    3. 目标和情感：人物的目标、愿望、困惑等情感表达，尽可能详细地描述其内心变化、冲突等。
    4. 背景信息：对话中提到的设定、背景信息（如游戏设定、小说设定等）、新的知识等，需要确保其准确无遗漏。
    5. 逻辑清晰：确保提取的内容逻辑连贯，避免遗漏重要细节，并与对话内容保持一致。
    6. 忽略无关紧要的信息,为了节约计算空间,除非用户在聊天记录中提了要重点记忆,一些日常不必记忆(寒暄,问候等无关紧要的信息,这个很重要,你要学会判断关键信息),但是用户告诉你的知识必须要记住。
    7. 如果用户在聊天过程中先给出了错误信息,但是在之后的对话中更正了正确的信息,请不要保存错误的信息,只保留正确的信息
    请将提取的内容以自然语言的方式呈现，确保完整表达对话中的关键要素。输出应为文本形式，并保留所有细节。
    与其对话的用户的名字叫(neko)记忆时用户用neko指代
    """},
            {"role": "user", "content": str(聊天记录)}]

    输出 = str(语言模型(信息))
    新记忆子图 = 输入信息生成知识图谱(输出)
    新记忆图 = 合成图(图, 新记忆子图)
    print("成功执行:更新记忆函数")
    return 新记忆图


def 临时更新记忆函数(图, 更新记忆):
    输出 = 更新记忆
    新记忆子图 = 输入信息生成知识图谱(输出)
    新记忆图 = 合成图(图, 新记忆子图)
    print("成功执行:更新记忆函数")
    return 新记忆图


def 检查或加载记忆图():
    文件名 = "记忆图.pkl"
    try:
        # 尝试读取 JSON 文件并加载图
        with open(文件名, "rb") as f:
            记忆图 = pickle.load(f)  # 将 JSON 数据转换为图
    except FileNotFoundError:
        # 如果文件不存在，创建一个新的空图
        记忆图 = nx.Graph()

    # 保存图为 JSON 格式
    保存图为_json(记忆图, 文件名)

    return 记忆图


def 保存图为_json(图, 文件名):
    with open(文件名, "wb") as f:
        pickle.dump(图, f)


def 加载图从_json(文件名):
    with open(文件名, "rb") as f:
        图 = pickle.load(f)
    return 图


def 计算消息字符数(消息):
    # 初始化总字符数
    总字符数 = 0

    # 遍历消息列表，累加每条消息的字符数
    for 消息项 in 消息:
        总字符数 += len(消息项["content"])

    return 总字符数


def 更新性格与设定(源性格, 聊天记录):
    聊天记录 = [entry for entry in 聊天记录 if entry["role"] != "system"]
    信息 = [{"role": "system", "content": """
        根据以下聊天记录修改机器人设定。原始设定为：
        
        """ + 源性格 + """
        
        注意:请根据聊天内容中用户的要求调整设定，确保输出的设定保持原始格式，并且修改后符合用户的新要求。如果用户要求改变说话方式或性格，务必在设定中进行相应调整。请只输出修改后的设定，不要包含其他内容
        ,如用户没做特殊要求,可不做修改,直接输出原始设定(感受聊天的氛围,灵活修改)。
        """},
            {"role": "user", "content": "聊天记录" + str(聊天记录)}
            ]
    输出 = 语言模型(信息)
    print("成功执行:更新性格与设定")
    return 输出


def 判断是否启用检索记忆(输入, 聊天记录):
    聊天记录 = [entry for entry in 聊天记录 if entry["role"] != "system"]
    信息 = [{"role": "system", "content": """
            根据聊天记录和当前用户输入: """ + 输入 + """
            判断是否启用记忆检索,如果需要则输出{{是}}否则输出{{否}}
        """},
            {"role": "user", "content": "聊天记录" + str(聊天记录)}
            ]
    输出 = 语言模型(信息)
    return 输出


def 文字转语音(输入):
    engine.say(输入)
    engine.runAndWait()


def 文字转语音AI(输入):
    engine.say(输入)
    engine.runAndWait()


def 检测并执行深层记忆函数(模型输出, 记忆图):
    # 正则匹配 {+函数名(参数1, "参数2")+} 格式
    匹配模式 = r"\{\+([\w\u4e00-\u9fa5_]+)\((\d+),\s*\"([^\"]+)\"\)\+\}"
    匹配结果 = re.search(匹配模式, 模型输出)

    if 匹配结果:
        # 提取函数名和参数
        函数名 = 匹配结果.group(1)
        参数1 = int(匹配结果.group(2))
        参数2 = 匹配结果.group(3)
        print(参数1)
        # 尝试执行对应函数
        try:
            if 参数1 >= 50:
                print("---------启动链式记忆----------")
                return 提取问题(记忆图, 参数2)
            if 函数名 == "启动深层记忆":
                print("---------启动深层记忆----------")
                return 启动深层记忆(参数1, 参数2, 记忆图)
            if 函数名 == "启动记忆函数":
                print("---------启动记忆函数----------")
                临时更新记忆函数(记忆图, 参数2)
                return None
            else:
                print("---------未启动深层记忆0----------")
                return None
        except Exception as e:
            print(f"错误：{e} - 指令无效，未能执行 {函数名}")
            return None
    else:
        print("---------未启动深层记忆1----------")
        return None


def 启动深层记忆(检索深度, 检索词, 记忆图):
    图数组 = 检索图函数(记忆图, 检索词, 4, 0.6, 检索深度, 20)
    提取记忆 = 提取整理记忆(图数组)
    return 提取记忆
    # 实现深层记忆检索的逻辑


def 为节点和边添加日期(图):
    """
    为图中的所有节点和边添加当前日期。
    :param 图: networkx 图对象
    """
    当前日期 = datetime.now().isoformat()  # 获取当前时间，格式为 ISO 8601

    # 为每个节点添加日期
    for 节点 in 图.nodes:
        属性 = 图.nodes[节点]["属性"]
        if len(属性) == 6:  # 如果节点尚未包含日期
            属性.append(当前日期)  # 添加日期
            图.nodes[节点]["属性"] = 属性

    # 为每条边添加创建日期
    for 边 in 图.edges:
        边属性 = 图.edges[边]["属性"]
        if "创建日期" not in 边属性:  # 如果边尚未包含创建日期
            边属性["创建日期"] = 当前日期  # 添加创建日期
            图.edges[边]["属性"] = 边属性


# def 获取节点周围的边(图, 节点):
#     # 获取节点周围的所有边及其属性
#     边列表 = 图.edges(节点, data=True)
#     数据 = ""
#
#     for 节点1, 节点2, 属性 in 边列表:
#         距离 = 属性.get('距离', '未知')  # 如果没有距离字段，返回 '未知'
#         边属性 = 属性.get("属性", "未知")  # 如果没有属性字段，返回 '未知'
#         添加日期 = 属性.get("创建日期", "未知")  # 如果没有创建日期字段，返回 '未知'
#
#         数据 += f"实体1: {节点1}, 实体2: {节点2}, 属性: {边属性}, 距离: {距离}, 添加日期: {添加日期}\n"
#     return 数据


def 扩散传播记忆算法(图, 输入):
    def 生成信息模板(输入, 节点, 数据, 转跳次数=0):
        return [
            {"role": "system", "content": f"""
        用户需要查找与:"{输入}"有关的信息,
        判断下面列出来的记忆图节点和边的属性是否有你需要的信息,当前节点为:"{节点}",你可以选择:
        1.跳转:如果你认为下一个节点有可用信息则跳转到下一个节点,检索下一个节点的边属性和与其相邻的节点,你将输出"{{跳转(节点名)}}"(双引号内的内容)注意你只可以转跳到下面列出来的节点,且不可选择当前节点;
        2.扩散:如果你觉得当前节点已经包含问题的基本信息,则选择扩散当前节点,你将输出"{{扩散(x)}}"(双引号内的内容),注意x是检索深度,10-30之间输出时把x替换成10-30的数,数越大扩散力度越大,扩散力度你自行判断;
        3.停止:如果你转跳过多比如5次以上则停止转跳,有一种情况例外就是你认为当前还有继续转跳的必要请继续转跳,否则扩散或停止,要停止时你将输出"{{停止}}"(双引号内的内容);
        如果有某些节点相似或者相同请转跳到添加日期最新的边上的节点(时间最新优先原则)。
        你已经转跳: {转跳次数} 次
        
        请严格按照格式输出!你只能输出下面的格式
        {{扩散(x)}}
        {{跳转(节点名)}}
        {{停止}}
                    """},
            {"role": "user", "content": f"记忆图节点和边的属性:{数据}"}
        ]

    def 处理输出(输出, 当前节点):
        """解析语言模型的输出并返回操作类型和参数"""
        if 输出.startswith("{跳转(") and 输出.endswith(")}"):
            return "跳转", 输出[4:-2]
        elif 输出.startswith("{扩散(") and 输出.endswith(")}"):
            return "扩散", float(输出[4:-2])
        elif 输出 == "{停止}":
            return "停止", None
        else:
            raise ValueError(f"无法解析的输出: {输出}")

    # 初始化
    嵌入向量 = model.encode(输入, task="text-matching")
    节点 = 找相似节点(图, 嵌入向量, 1, 0)[0]
    转跳次数 = 0

    while 转跳次数 <= 10:
        数据 = 获取节点周围的边(图, 节点)
        信息 = 生成信息模板(输入, 节点, 数据, 转跳次数)
        输出 = 语言模型(信息)
        print(f"模型输出: {输出}")

        操作, 参数 = 处理输出(输出, 节点)

        if 操作 == "跳转":
            节点 = 参数
            转跳次数 += 1
        elif 操作 == "扩散":
            图数组 = 检索图函数(图, 节点, 1, 0, 参数, 15)
            return 提取整理记忆(图数组)
        elif 操作 == "停止":
            图数组 = 检索图函数(图, 节点, 1, 0, 10, 10)
            return 提取整理记忆(图数组)

    # 超过最大转跳次数默认停止
    print("达到最大转跳次数，默认停止。")
    图数组 = 检索图函数(图, 节点, 1, 0, 10, 10)
    return 提取整理记忆(图数组)


def 提取问题(图, 输入):
    最大尝试次数 = 6
    尝试次数 = 0

    while 尝试次数 < 最大尝试次数:
        尝试次数 += 1
        print(f"尝试第 {尝试次数} 次扩散...")

        # 执行扩散传播记忆算法
        输出 = 扩散传播记忆算法(图, 输入)

        # 构造信息模板
        信息 = [
            {"role": "system", "content": f"""
                根据以下信息回答 "{输入}",
                如果没有可用信息请输出 {{重启}}。
            """},
            {"role": "user", "content": "聊天记录: " + str(输出)}
        ]

        # 调用语言模型处理
        最后目标 = 语言模型(信息)
        print(f"语言模型输出: {最后目标}")

        # 检查模型输出是否包含 "{重启}"
        if "{重启}" in 最后目标:
            print("输出包含 {重启}，重新扩散...")
            continue  # 重新执行扩散传播
        else:
            return 最后目标  # 返回有用信息

    # 超过最大尝试次数
    print("超过最大尝试次数，未找到有用信息。")
    return "未能找到相关信息"


def 判断函数(输入1, 输入2, 聊天记录):
    信息 = [
        {"role": "system", "content": f"""
            
            根据聊天记录判断下面哪个回答更加符合要求:
            
                聊天记录:""{str(聊天记录)}"",
    
                要求如下:
                **只能根据历史聊天记录和通过RAG生成的记忆信息**进行回答，不能凭空捏造任何信息。
                回答的依据只能是已有的聊天记录和记忆信息，面对未知内容时应该坦诚表示自己不知道。

                
             如果回答1好就回复{{回答1}},回答2好就回复{{回答2}}
            。
        """},
        {"role": "user", "content":
            f"""   回答1.""{输入1}"",
                回答2.""{输入2}"",
                """
         }
    ]
    输出1 = 语言模型(信息)
    print(输出1)
    return 输出1


def 利用语言模型拆分长设定(长设定, 最大重试次数=5):
    重试次数 = 0

    while 重试次数 < 最大重试次数:
        模型输入 = [
            {"role": "system",
             "content": "请将以下特别长的设定拆分成多个清晰的段,10个左右,信息必须完整，以 JSON 格式输出。格式如下：\n{\"设定块\": [\"小段1\", \"小段2\", ...]}"},
            {"role": "user", "content": 长设定}
        ]
        模型输出 = 语言模型(模型输入)  # 调用语言模型

        if 模型输出.startswith("```json") and 模型输出.endswith("```"):
            模型输出 = 模型输出[7:-3].strip()  # 去掉 ```json 和 ```
        try:
            # 尝试解析 JSON 格式
            输出字典 = json.loads(模型输出)

            if "设定块" in 输出字典 and isinstance(输出字典["设定块"], list):
                最后输出 = 输出字典["设定块"]
                print(最后输出)
                return 最后输出  # 返回设定块列表
        except json.JSONDecodeError:
            pass

        # 如果格式错误，增加重试次数
        重试次数 += 1
        print(f"格式错误，正在重试...（第 {重试次数} 次）")

    # 如果超过最大重试次数
    raise ValueError("语言模型输出多次不符合 JSON 格式！")


def 长信息记忆图构建(信息):
    输出图 = nx.Graph()
    信息数组 = 利用语言模型拆分长设定(信息)
    for 子输入 in 信息数组:
        图 = 输入信息生成知识图谱(子输入)
        输出图 = 合成图(输出图, 图)
    return 输出图


